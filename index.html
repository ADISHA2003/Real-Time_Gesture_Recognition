<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Gesture Recognizer</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      text-align: center;
      padding: 20px;
      background-color: #f4f4f9;
    }

    h1 {
      color: #333;
    }

    video, canvas {
      margin-top: 20px;
      border: 1px solid #ccc;
    }

    #gesture-output {
      margin-top: 20px;
      font-size: 1.5em;
      color: #007BFF;
    }

    #response-output {
      margin-top: 10px;
      font-size: 1.2em;
      color: green;
    }

    button {
      margin-top: 20px;
      padding: 10px 20px;
      font-size: 1em;
      background-color: #007BFF;
      color: white;
      border: none;
      border-radius: 5px;
      cursor: pointer;
    }

    button:hover {
      background-color: #0056b3;
    }
  </style>
</head>
<body>
  <h1>Gesture Recognition</h1>
  <video id="webcam" autoplay playsinline width="640" height="480"></video>
  <canvas id="output-canvas" width="640" height="480"></canvas>
  <p id="gesture-output">Gesture: <span id="gesture-name">None</span></p>
  <p id="response-output">Response: Waiting for gesture...</p>
  <button id="start-button">Enable Webcam</button>

  <script type="module">
    import {
      GestureRecognizer,
      FilesetResolver
    } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3";

    const webcamElement = document.getElementById("webcam");
    const canvasElement = document.getElementById("output-canvas");
    const canvasCtx = canvasElement.getContext("2d");
    const gestureOutput = document.getElementById("gesture-name");
    const responseOutput = document.getElementById("response-output");
    const startButton = document.getElementById("start-button");

    let gestureRecognizer;
    let webcamRunning = false;

    const initGestureRecognizer = async () => {
      const filesetResolver = await FilesetResolver.forVisionTasks(
        "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm"
      );

      gestureRecognizer = await GestureRecognizer.createFromOptions(filesetResolver, {
        baseOptions: {
          modelAssetPath: "https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task",
          delegate: "GPU",
        },
        runningMode: "VIDEO",
      });
      console.log("Gesture Recognizer Initialized");
    };

    const startWebcam = async () => {
      if (!gestureRecognizer) {
        alert("Model not loaded yet. Please wait...");
        return;
      }

      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true });
        webcamElement.srcObject = stream;
        webcamRunning = true;
        predictGesture();
      } catch (error) {
        alert("Error accessing the webcam. Please ensure it's enabled.");
        console.error(error);
      }
    };

    const predictGesture = async () => {
      if (!webcamRunning) return;

      const nowInMs = Date.now();
      const results = await gestureRecognizer.recognizeForVideo(webcamElement, nowInMs);

      // Clear the canvas
      canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);

      if (results.landmarks) {
        for (const landmarks of results.landmarks) {
          drawLandmarks(landmarks);
        }
      }

      if (results.gestures.length > 0) {
        const recognizedGesture = results.gestures[0][0].categoryName;
        gestureOutput.innerText = recognizedGesture;
        provideResponse(recognizedGesture);
      } else {
        gestureOutput.innerText = "None";
        responseOutput.innerText = "Waiting for gesture...";
      }

      requestAnimationFrame(predictGesture);
    };

    const drawLandmarks = (landmarks) => {
      landmarks.forEach((point) => {
        canvasCtx.beginPath();
        canvasCtx.arc(point.x * canvasElement.width, point.y * canvasElement.height, 5, 0, 2 * Math.PI);
        canvasCtx.fillStyle = "#FF0000";
        canvasCtx.fill();
      });
    };

    const provideResponse = (gesture) => {
      const responses = {
        "Thumb_Up": "Great! üëç",
        "Thumb_Down": "Oh no! üëé",
        "Victory": "Peace! ‚úåÔ∏è",
        "Open_Palm": "Hello! üëã",
      };

      responseOutput.innerText = responses[gesture] || "Unknown gesture.";
    };

    startButton.addEventListener("click", startWebcam);

    // Initialize the gesture recognizer
    initGestureRecognizer();
  </script>
</body>
</html>
